# -*- coding: utf-8 -*-
"""RNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wZLODbKWSWcNb2qYKkHF9HVwIxijhv8n
"""

import os
os.environ['PYTHONHASHSEED'] = '0'
import random as rn   
import numpy as np
np.random.seed(1)
rn.seed(3)
import tensorflow 
tensorflow.random.set_seed(2)
import pandas as pd
import matplotlib.pyplot as plt
from keras.models import Sequential, load_model
from keras.layers.core import Dense
#from keras.layers.recurrent import SimpleRNN
from keras import optimizers
from keras.callbacks import EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score
from math import sqrt
import datetime as dt
import time
plt.style.use('ggplot')

df_1 = pd.read_csv('/content/drive/My Drive/CSV.csv',parse_dates = True,index_col=0)
df_1.tail()

df_1['Close'].plot()

#Correlation matrix
df_1.corr()['Close']

# Distribution of Various Features
print(df_1.describe().Volume) 
df_1.drop(df_1[df_1['Volume']==0].index, inplace = True) #Dropping rows with volume value 0
df_1['Volume'].hist(bins = 10)

# Scheduling an early stop
earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=80, verbose=1, mode='min')
callbacks_list = [earlystop]

#Build and train the model
def fit_model(time_steps,hl,lr,batch,epochs,train,val):
    xtrain = []
    ytrain = []
    xval = []
    yval = []

    # For loop in training data
    for i in range(time_steps,train.shape[0]):
        xtrain.append(train[i-time_steps:i])
        xtrain.append(train[i][0])
    xtrain,ytrain = np.array(xtrain),np.array(ytrain)
  
    # For loop in validation data
    for i in range(time_steps,val.shape[0]):
        xval.append(val[i-time_steps:i])
        yval.append(val[i][0])
    xval,yval = np.array(xval),np.array(yval)
    
    # Adding Layers to the model
    model_1 = Sequential()
    model_1.add(SimpleRNN(xtrain.shape[2],input_shape = (xtrain.shape[1],xtrain.shape[2]),return_sequences = True,
                        activation = 'relu'))
    for i in range(len(hl)-1):        
        model_1.add(SimpleRNN(hl[i],activation = 'relu',return_sequences = True))
    model_1.add(SimpleRNN(hl[-1],activation = 'relu'))
    model_1.add(Dense(1))
    model_1.compile(optimizer = tensorflow.optimizers.Adam(lr = lr), loss = 'mean_squared_error')
    print(model_1.summary())
  
    # Training the data
    history = model_1.fit(xtrain,ytrain,epochs = epochs,batch_size = batch,validation_data = (xval, yval),verbose = 0,
                        shuffle = False, callbacks=callbacks_list)
    model_1.reset_states()
    return  history.history['loss'], history.history['val_loss'],model_1

# Evaluating the Stock Prediction model
def evaluate_model(model_1,test,time_steps):
    xtest = []
    xtest = []

    # For loop in training data
    for i in range(time_steps,test.shape[0]):
        xtest.append(test[i-time_steps:i])
        ytest.append(test[i][0])
    xtest,ytest = np.array(xtest),np.array(ytest)
    #print(X_test.shape,Y_test.shape)
  
    # Prediction 
    yhat = model.predict(xtest)
    mse = mean_squared_error(ytest,yhat)
    rmse = sqrt(mse)
    r = r2_score(ytest,yhat)
    return ytest, yhat,mse, rmse, r

# Plotting the predictions
def plot_data(ytest,yhat):
    plt.plot(ytest,c = 'r')
    plt.plot(yhat,c = 'y')
    plt.xlabel('Day')
    plt.ylabel('Price')
    plt.title("Stock Price Prediction using Multivatiate-RNN")
    plt.legend(['Actual','Predicted'],loc = 'lower right')
    plt.show()

# Plotting the training errors
def plot_error(train_loss,val_loss):
    plt.plot(train_loss,c = 'r')
    plt.plot(val_loss,c = 'b')
    plt.ylabel('Loss')
    plt.xlabel('Epochs')
    plt.title('Loss Plot')
    plt.legend(['train','val'],loc = 'upper right')
    plt.show()

# Extracting the series
series_ = df_1[['Close','High','Volume']] # Picking the multivariate series 
print(series_.shape)
print(series_.tail())

# Train Val Test Split
train_end_ = dt.date(2006,12,31)
train_start_ = dt.date(1997,1,1)
train_data_ = series_.loc[train_start_:train_end_]

val_start_ = dt.date(2007,1,1)
val_end_ = dt.date(2008,12,31)
val_data_ = series_.loc[val_start_:val_end_]

test_start_ = dt.date(2009,1,1)
test_end_ = dt.date(2010,12,31)
test_data_ = series_.loc[test_start_:test_end_]

print(train_data_.shape,val_data_.shape,test_data_.shape)

# Normalisation
sc = MinMaxScaler()
train = sc.fit_transform(train_data_)
val = sc.transform(val_data_)
test = sc.transform(test_data_)
print(train.shape,val.shape,test.shape)

time_steps = 30
hl = [50,45]
lr = 1e-3
batch_size = 32
num_epochs = 200

train_error,val_error,model_1 = fit_model(time_steps,hl,lr,batch_size,num_epochs,train,val)

true,predicted,mse, rmse, r = evaluate_model(model_1,test,30)
print(mse)
print(rmse)
print(r2_value)
plot_data(true,predicted)

# Save a model
model.save('MV3-RNN_30_[50,45]_1e-3_32.h5')
del model # Deletes the model

# Hyperparameters
time_steps = 30
hl = [50,45] 
lr = 1e-3
batch_size = 32
num_epochs = 50

# Extracting the series
series_ = df_1[['Close','High','Volume']] # Picking the multivariate series 
print(series_.shape)
print(series_.tail())

# Normalisation
sc = MinMaxScaler()
series_ = sc.fit_transform(series_[:5400])

#Splitting the data for initial model creation
splits = 5
split_size = 600
train = series[:3*split_size]
test = series[3*split_size:4*split_size]

cross_val_results = list()
train_loss = pd.DataFrame()
val_loss = pd.DataFrame()
model_1,train_error,val_error = fit_model(time_steps,hl,lr,batch_size,num_epochs,train,val)
train_loss['Split1'] = train_error
val_loss['Split1'] = val_error
true,predicted,mse, rmse, r = evaluate_model(model_1,test,time_steps)
print("Split 1")
print(mse)
print(mse)
print(rmse)
print(r2_value)
plot_data(true,predicted)
cross_val_results.append([mse,rmse,r2_value,0])
model.save("MV3-RNN-Split1.h5")

train = series[:4*split_size]
test = series[4*split_size:5*split_size]
xtrain,ytrain = [],[]
# For loop in training data
for i in range(time_steps,train.shape[0]):
    xtrain.append(train[i-timesteps:i])
    ytrain.append(train[i][0])
xtrain,ytrain = np.array(xtrain),np.array(ytrain)

start = time.time()
history = model_1.fit(xtrain,ytrain,epochs = num_epochs,batch_size = batch_size,validation_split = 0.2,verbose = 0,
                    shuffle = False)
end = time.time()   
train_loss["Split2"] = history.history['loss']
val_loss["Split2"] = history.history['val_loss']
true,predicted,mse, rmse, r = evaluate_model(model_1,test,time_steps)
print("Split 2")
print(mse)
print(rmse)
print(r2_value)
plot_data(true,predicted)
cross_val_results.append([mse,rmse,r2_value,end-start])
model.save("MV3-RNN-Split2.h5")

train = series[:5*split_size]
test = series[5*split_size:6*split_size]
xtrain,ytrain = [],[]
# For loop in training data
for i in range(timesteps,train.shape[0]):
    xtrain.append(train[i-timesteps:i])
    ytrain.append(train[i][0])
xtrain,ytrain = np.array(xtrain),np.array(ytrain)

start = time.time()
history = model.fit(xtrain,ytrain,epochs = num_epochs,batch_size = batch_size,validation_split = 0.2,verbose = 0,
                    shuffle = False)
end = time.time()   
train_loss["Split3"] = history.history['loss']
val_loss["Split3"] = history.history['val_loss']
true,predicted,mse, rmse, r = evaluate_model(model_1,test,time_steps)
print("Split 3")
print(mse)
print(rmse)
print(r2_value)
plot_data(true,predicted)
cross_val_results.append([mse,rmse,r2_value,end-start])
model.save("MV3-RNN-Split3.h5")

train = series[:6*split_size]
test = series[6*split_size:7*split_size]
xtrain,ytrain = [],[]
# For loop in training data
for i in range(timesteps,train.shape[0]):
    xtrain.append(train[i-timesteps:i])
    ytrain.append(train[i][0])
xtrain,ytrain = np.array(xtrain),np.array(ytrain)

start = time.time()
history = model.fit(xtrain,ytrain,epochs = num_epochs,batch_size = batch_size,validation_split = 0.2,verbose = 0, shuffle = False)
end = time.time() 
train_loss["Split4"] = history.history['loss']
val_loss["Split4"] = history.history['val_loss']
true,predicted,mse, rmse, r = evaluate_model(model_1,test,time_steps)
print("Split 4")
print(mse)
print(rmse)
print(r2_value)
plot_data(true,predicted)
cross_val_results.append([mse,rmse,r2_value,end-start])
model.save("MV3-RNN-Split4.h5")

train = series[:7*split_size]
test = series[7*split_size:8*split_size]
xtrain,ytrain = [],[]
# For loop in training data
for i in range(time_steps,train.shape[0]):
    xtrain.append(train[i-time_steps:i])
    ytrain.append(train[i][0])
xtrain,ytrain = np.array(xtrain),np.array(ytrain)

start = time.time()
history = model.fit(xtrain,ytrain,epochs = num_epochs,batch_size = batch_size,validation_split = 0.2,verbose = 0,
                    shuffle = False)
end = time.time()   
train_loss["Split5"] = history.history['loss']
val_loss["Split5"] = history.history['val_loss']
true,predicted,mse, rmse, r = evaluate_model(model_1,test,time_steps)
print("Split 5")
print(mse)
print(rmse)
print(r2_value)
plot_data(true,predicted)
cross_val_results.append([mse,rmse,r2_value,end-start])
model.save("MV3-RNN-Split5.h5")

CV_results = pd.DataFrame(cross_val_results,columns=['MSE','RMSE','R2_Score','Train_Time'])
print("Avg. MSE = {}".format(CV_results['MSE'].mean()))
print("Avg. RMSE = {}".format(CV_results['RMSE'].mean()))
print("Avg. R2-score = {}".format(CV_results['R2_Score'].mean()))

CV_results.to_csv('MV3-RNN_CrossValidation.csv')
train_loss.to_csv('MV3-RNN_CrossValidation_TrainLoss.csv')
val_loss.to_csv('MV3-RNN_CrossValidation_ValLoss.csv')